{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NGram.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNGcpnusVRBS"
      },
      "source": [
        "import string\n",
        "import re\n",
        "import random\n",
        "import time\n",
        "from typing import List\n",
        "import io\n",
        "import keras\n",
        "import collections"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBq1yKNOHkVd"
      },
      "source": [
        "def get_data():\n",
        "    path = keras.utils.get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
        "\n",
        "    with io.open(path, encoding='utf-8') as file:\n",
        "      raw_text = file.read()\n",
        "\n",
        "    processed_text = raw_text.lower()\n",
        "    processed_text = processed_text.replace('\\n', ' ').replace('\\r', '')\n",
        "    processed_text = re.sub(r'[\\d=_]', r'', processed_text)\n",
        "    processed_text = re.sub(r'(?=[\",;:()])(?<=[^\\s])', r' ', processed_text) # adding spaces around punctuations\n",
        "    processed_text = re.sub(r'(?<=[\",;:()])(?=[^\\s])', r' ', processed_text) # adding spaces around punctuations\n",
        "    processed_text = re.sub(r'(?<=[^\\s])(--)', r' --', processed_text) # adding spaces around punctuations\n",
        "    processed_text = re.sub(r'(--)(?=[^\\s])', r'-- ', processed_text) # adding spaces around punctuations\n",
        "    # print(processed_text)\n",
        "    return processed_text\n",
        "\n",
        "data = get_data()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMOhkSCjTmDJ"
      },
      "source": [
        "def create_ngram_info(n, data):\n",
        "    # sentences = re.split('[?!. ]', data)\n",
        "    sentences = data.split()\n",
        "    word_frequencies = collections.Counter(sentences)\n",
        "\n",
        "    ngram_frequencies = {} # maps tuples to ints\n",
        "    candidates_for_contexts = {} # maps tuples to sets\n",
        "    for i in range(n, len(sentences)-1):\n",
        "        # print(sentences[i-1])\n",
        "        gram = [sentences[i-x] for x in reversed(range(n))]\n",
        "        gram = tuple(gram)\n",
        "        # print(\"Key: \", i, ngram)\n",
        "\n",
        "        context = gram[:n-1]\n",
        "        current = gram[-1]\n",
        "        # print(\"Context: \", i, context)\n",
        "\n",
        "        ngram_frequencies[gram] = ngram_frequencies.get(gram,0) + 1\n",
        "\n",
        "        current_context = candidates_for_contexts.get(context,0)\n",
        "        updated_context = current_context.add(current) if current_context else {current}\n",
        "        candidates_for_contexts[context] = updated_context\n",
        "\n",
        "    ngram_probabilities = {}\n",
        "    for n in ngram_frequencies.keys():\n",
        "        probability = ngram_frequencies.get(n) / float(word_frequencies[n[-1]])\n",
        "        ngram_probabilities[n] = probability \n",
        "    \n",
        "    return ngram_frequencies, candidates_for_contexts, ngram_probabilities\n",
        "\n",
        "ngram_frequencies, candidates_for_contexts, ngram_probabilities = create_ngram_info(3, data)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pYsRi-acWNH"
      },
      "source": [
        "\"\"\"\n",
        "Chooses the most likely next word\n",
        "\"\"\"\n",
        "def get_next_word(context):\n",
        "    candidates = candidates_for_contexts.get(tuple(context), set())\n",
        "    print(\"candidate type: \", type(candidates))\n",
        "    candidates = list(candidates)\n",
        "    print(\"candidates: \", candidates)\n",
        "    if(not candidates):\n",
        "        return '.'\n",
        "\n",
        "    print(candidates)\n",
        "    probabilities = [ngram_probabilities.get(context.append(c),0) for c in candidates]\n",
        "    min_indexes = [i for i, x in enumerate(probabilities) if x == min(probabilities)]\n",
        "    print(min_indexes)\n",
        "    first = min_indexes[0]\n",
        "\n",
        "    selected_candidate = candidates[first] # can do more randomization\n",
        "\n",
        "    return selected_candidate\n",
        "     \n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_RNFaQ0cb5d"
      },
      "source": [
        "def generate_sentence(n=3, min_words=10, max_words=20):\n",
        "    sentence_length = random.randint(min_words, max_words)\n",
        "    print(sentence_length)\n",
        "\n",
        "    new_sentence = []\n",
        "    for w in range(sentence_length):\n",
        "        if len(new_sentence) > n:\n",
        "            context = new_sentence[-n:]\n",
        "            # print(\"here\")\n",
        "        else:\n",
        "            context = new_sentence # pad the front\n",
        "            # print(context)\n",
        "        new_word = get_next_word(context)\n",
        "        new_sentence.append(new_word)\n",
        "\n",
        "    return ' '.join(new_sentence)\n",
        "\n",
        "generate_sentence()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fWw-j-IUg6M"
      },
      "source": [
        "def main():\n",
        "    data = get_data()\n",
        "    ngram_frequencies, candidates_for_contexts, ngram_probabilities = create_ngram_info(3, data)\n",
        "\n",
        "    # random.seed(45)\n",
        "    # desired_output_length = 30\n",
        "    # seed_text = \"We are\"\n",
        "    n = 3\n",
        "\n",
        "    ngram_prediction = generate_sentence(n=3)\n",
        "    \n",
        "    print(\"\\nNGRAM generated: \", ngram_prediction)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}